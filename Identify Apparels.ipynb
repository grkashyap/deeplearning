{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for Apparel classification\n",
    "\n",
    "Dataset - https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-apparels/\n",
    "\n",
    "Accuracy - 89.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages to load images\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "curDir = os.path.curdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = os.path.join(curDir,'train_Images/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob(os.path.join(train_images, \"*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\train_Images/train\\\\1.png',\n",
       " '.\\\\train_Images/train\\\\10.png',\n",
       " '.\\\\train_Images/train\\\\100.png',\n",
       " '.\\\\train_Images/train\\\\1000.png',\n",
       " '.\\\\train_Images/train\\\\10000.png']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img = cv.imread(images[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x236e5bc2cf8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read train.csv\n",
    "train_data = pd.read_csv('train_images/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1      9\n",
       "1   2      0\n",
       "2   3      0\n",
       "3   4      3\n",
       "4   5      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_SIZE = int(len(images) * 0.8)\n",
    "CV_DATASET_SIZE    = int(len(images) * 0.1)\n",
    "TEST_DATASET_SIZE  = int(len(images) * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n",
      "6000\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "print(TRAIN_DATASET_SIZE)\n",
    "print(CV_DATASET_SIZE)\n",
    "print(TEST_DATASET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_shuffled = np.random.shuffle(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = os.path.basename(images[10]).split('.')[0]\n",
    "sample_label = train_data[train_data['id'] == int(sample_image)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15786\n"
     ]
    }
   ],
   "source": [
    "print(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15785</th>\n",
       "      <td>15786</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label\n",
       "15785  15786      5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_for_training():\n",
    "    '''\n",
    "        Read and return images in train images and their corresponding labels\n",
    "    '''\n",
    "    x_train = []\n",
    "    x_cv    = []\n",
    "    x_test  = []\n",
    "    \n",
    "    y_train = []\n",
    "    y_cv    = []\n",
    "    y_test  = []\n",
    "    \n",
    "    IMG_HEIGHT = 128\n",
    "    IMG_WIDTH  = 128\n",
    "    \n",
    "    num_images_loaded = 0;\n",
    "    \n",
    "    #load train data\n",
    "    for img in images[:TRAIN_DATASET_SIZE]:\n",
    "        train_img = cv.imread(img)\n",
    "        img_name = os.path.basename(img).split('.')[0]\n",
    "        train_label = train_data[train_data['id'] == int(img_name)]['label'].values[0]\n",
    "        \n",
    "        #x_train.append(cv.resize(train_img,(IMG_WIDTH,IMG_HEIGHT),interpolation=cv.INTER_CUBIC))\n",
    "        x_train.append(train_img)\n",
    "        y_train.append(train_label)\n",
    "        \n",
    "        num_images_loaded += 1\n",
    "        \n",
    "        if(num_images_loaded % 1000 == 0):\n",
    "            print('{} training images loaded'.format(num_images_loaded))\n",
    "        \n",
    "    print('-------------------------Loaded training dataset-------------------------------')\n",
    "    \n",
    "    num_images_loaded = 0;\n",
    "    \n",
    "    #load cross validation data\n",
    "    for img in images[TRAIN_DATASET_SIZE:TRAIN_DATASET_SIZE+CV_DATASET_SIZE]:\n",
    "        cv_img = cv.imread(img)\n",
    "        img_name = os.path.basename(img).split('.')[0]\n",
    "        cv_label = train_data[train_data['id'] == int(img_name)]['label'].values[0]\n",
    "        \n",
    "        #x_cv.append(cv.resize(cv_img,(IMG_WIDTH,IMG_HEIGHT),interpolation=cv.INTER_CUBIC))\n",
    "        x_cv.append(cv_img)\n",
    "        y_cv.append(cv_label)\n",
    "        \n",
    "        num_images_loaded += 1\n",
    "        \n",
    "        if(num_images_loaded % 1000 == 0):\n",
    "            print('{} cross validation images loaded'.format(num_images_loaded))\n",
    "        \n",
    "    print('-------------------------Loaded cross validation dataset-------------------------------')\n",
    "    \n",
    "    num_images_loaded = 0;\n",
    "    \n",
    "    #load test data\n",
    "    for img in images[TRAIN_DATASET_SIZE+CV_DATASET_SIZE:]:\n",
    "        test_img = cv.imread(img)\n",
    "        img_name = os.path.basename(img).split('.')[0]\n",
    "        test_label = train_data[train_data['id'] == int(img_name)]['label'].values[0]\n",
    "        \n",
    "        #x_test.append(cv.resize(test_img,(IMG_WIDTH,IMG_HEIGHT),interpolation=cv.INTER_CUBIC))\n",
    "        x_test.append(test_img)\n",
    "        y_test.append(test_label)\n",
    "        \n",
    "        num_images_loaded += 1\n",
    "        \n",
    "        if(num_images_loaded % 1000 == 0):\n",
    "            print('{} testing images loaded'.format(num_images_loaded))\n",
    "        \n",
    "    print('-------------------------Loaded testing dataset-------------------------------')\n",
    "        \n",
    "    return x_train, y_train, x_cv, y_cv, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 training images loaded\n",
      "2000 training images loaded\n",
      "3000 training images loaded\n",
      "4000 training images loaded\n",
      "5000 training images loaded\n",
      "6000 training images loaded\n",
      "7000 training images loaded\n",
      "8000 training images loaded\n",
      "9000 training images loaded\n",
      "10000 training images loaded\n",
      "11000 training images loaded\n",
      "12000 training images loaded\n",
      "13000 training images loaded\n",
      "14000 training images loaded\n",
      "15000 training images loaded\n",
      "16000 training images loaded\n",
      "17000 training images loaded\n",
      "18000 training images loaded\n",
      "19000 training images loaded\n",
      "20000 training images loaded\n",
      "21000 training images loaded\n",
      "22000 training images loaded\n",
      "23000 training images loaded\n",
      "24000 training images loaded\n",
      "25000 training images loaded\n",
      "26000 training images loaded\n",
      "27000 training images loaded\n",
      "28000 training images loaded\n",
      "29000 training images loaded\n",
      "30000 training images loaded\n",
      "31000 training images loaded\n",
      "32000 training images loaded\n",
      "33000 training images loaded\n",
      "34000 training images loaded\n",
      "35000 training images loaded\n",
      "36000 training images loaded\n",
      "37000 training images loaded\n",
      "38000 training images loaded\n",
      "39000 training images loaded\n",
      "40000 training images loaded\n",
      "41000 training images loaded\n",
      "42000 training images loaded\n",
      "43000 training images loaded\n",
      "44000 training images loaded\n",
      "45000 training images loaded\n",
      "46000 training images loaded\n",
      "47000 training images loaded\n",
      "48000 training images loaded\n",
      "-------------------------Loaded training dataset-------------------------------\n",
      "1000 cross validation images loaded\n",
      "2000 cross validation images loaded\n",
      "3000 cross validation images loaded\n",
      "4000 cross validation images loaded\n",
      "5000 cross validation images loaded\n",
      "6000 cross validation images loaded\n",
      "-------------------------Loaded cross validation dataset-------------------------------\n",
      "1000 testing images loaded\n",
      "2000 testing images loaded\n",
      "3000 testing images loaded\n",
      "4000 testing images loaded\n",
      "5000 testing images loaded\n",
      "6000 testing images loaded\n",
      "-------------------------Loaded testing dataset-------------------------------\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_cv, y_cv, x_test, y_test  = load_images_for_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = os.path.join(curDir,'test_Images/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = glob(os.path.join(test_images, \"*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_images():\n",
    "    '''\n",
    "        Read images in test images and return the list\n",
    "    '''\n",
    "    x = []\n",
    "    img_name_lst = []\n",
    "    \n",
    "    IMG_HEIGHT = 128\n",
    "    IMG_WIDTH  = 128\n",
    "    \n",
    "    for img in test_imgs:\n",
    "        test_img = cv.imread(img)\n",
    "        #x.append(cv.resize(test_img,(IMG_WIDTH,IMG_HEIGHT),interpolation=cv.INTER_CUBIC))\n",
    "        x.append(test_img)\n",
    "        img_name = os.path.basename(img).split('.')[0]\n",
    "        img_name_lst.append(int(img_name))\n",
    "        \n",
    "        num_images_loaded = 0\n",
    "        num_images_loaded += 1\n",
    "        \n",
    "        if(num_images_loaded % 1000 == 0):\n",
    "            print('{} testing set images loaded'.format(num_images_loaded))\n",
    "            \n",
    "        \n",
    "        \n",
    "    print('-------------------------Loaded testing dataset-------------------------------')\n",
    "        \n",
    "    return x, img_name_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Loaded testing dataset-------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_x,img_name_lst = load_test_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data as numpy arrays\n",
    "np.save(\"tmp/Train_image_data\",x_train)\n",
    "np.save(\"tmp/Train_label_data\",y_train)\n",
    "\n",
    "#save cv data\n",
    "np.save(\"tmp/cv_image_data\",x_cv)\n",
    "np.save(\"tmp/cv_label_data\",y_cv)\n",
    "\n",
    "#save test data\n",
    "np.save(\"tmp/Test_image_data\",x_test)\n",
    "np.save(\"tmp/Test_label_data\",y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X,f,filters,stage,block):\n",
    "    '''\n",
    "        Method for identity block used in ResNet\n",
    "\n",
    "        Parameters:\n",
    "        X       -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "        f       -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "        filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "        stage   -- integer, used to name the layers, depending on their position in the network\n",
    "        block   -- string/character, used to name the layers, depending on their position in the network\n",
    "\n",
    "        Returns:\n",
    "        X       -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    '''\n",
    "    conv_name_base = 'res'+str(stage)+block+'_branch'\n",
    "    bn_name_base   = 'bn'+str(stage)+block+'_branch'\n",
    "    \n",
    "    F1,F2,F3 = filters\n",
    "    X_shortcut = X\n",
    "    \n",
    "    X = Conv2D(filters=F1,kernel_size=(1,1),strides=(1,1),padding='valid',name=conv_name_base+'2a',kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+'2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding='same',name=conv_name_base+'2b',kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+'2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding='valid',name=conv_name_base+'2c',kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+'2c')(X)\n",
    "    \n",
    "    X = Add()([X_shortcut,X])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X,f,filters,stage,block,strides=2):\n",
    "    \n",
    "    '''\n",
    "    Implementation of the convolutional block\n",
    "    \n",
    "    Parameters:\n",
    "    X       -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f       -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage   -- integer, used to name the layers, depending on their position in the network\n",
    "    block   -- string/character, used to name the layers, depending on their position in the network\n",
    "    strides -- Integer, specifying the stride to be used\n",
    "    \n",
    "    Returns:\n",
    "    X       -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    '''\n",
    "    \n",
    "    conv_name_base = 'res'+str(stage)+block+'_branch'\n",
    "    bn_name_base   = 'bn'+str(stage)+block+'_branch'\n",
    "    \n",
    "    F1,F2,F3 = filters\n",
    "    X_shortcut = X\n",
    "    \n",
    "    X = Conv2D(F1, (1, 1), strides = (strides,strides), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b', padding='same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (strides,strides), name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    X = Add()([X_shortcut,X])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=(28,28,3),classes=10):\n",
    "    \n",
    "    \"\"\"\n",
    "    Implementation of the ResNet50. Following is the architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Parameters:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes     -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model       -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    X = ZeroPadding2D((3,3))(X_input)\n",
    "    \n",
    "    X = Conv2D(28, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', strides = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', strides = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', strides = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', strides = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    X = AveragePooling2D(pool_size=(1, 1),name='avg_pool',dim_ordering='th')(X)\n",
    "    \n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `AveragePooling2D` call to the Keras 2 API: `AveragePooling2D(pool_size=(1, 1), name=\"avg_pool\", data_format=\"channels_first\")`\n"
     ]
    }
   ],
   "source": [
    "#Build model graph\n",
    "model = ResNet50(input_shape = (28, 28, 3), classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "X_train = np.load('tmp/Train_image_data.npy')\n",
    "Y_train = np.load('tmp/Train_label_data.npy')\n",
    "\n",
    "X_cv = np.load('tmp/cv_image_data.npy')\n",
    "Y_cv = np.load('tmp/cv_label_data.npy')\n",
    "\n",
    "X_test = np.load('tmp/Test_image_data.npy')\n",
    "Y_test = np.load('tmp/Test_label_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to convert labels to one-hot encoding\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert labels to one-hot encoding\n",
    "Y_train = convert_to_one_hot(Y_train, 10).T\n",
    "Y_cv = convert_to_one_hot(Y_cv, 10).T\n",
    "Y_test = convert_to_one_hot(Y_test, 10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 48000\n",
      "number of test examples = 6000\n",
      "X_train shape: (48000, 28, 28, 3)\n",
      "Y_train shape: (48000, 10)\n",
      "X_test shape: (6000, 28, 28, 3)\n",
      "Y_test shape: (6000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 347s 7ms/step - loss: 0.2791 - acc: 0.8984\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 347s 7ms/step - loss: 0.2525 - acc: 0.9067\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 340s 7ms/step - loss: 0.2934 - acc: 0.8918\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 339s 7ms/step - loss: 0.2455 - acc: 0.9069\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 339s 7ms/step - loss: 0.2232 - acc: 0.9168\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 381s 8ms/step - loss: 0.2070 - acc: 0.9228\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 371s 8ms/step - loss: 0.1964 - acc: 0.9250\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 366s 8ms/step - loss: 0.3176 - acc: 0.9100\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 353s 7ms/step - loss: 0.3572 - acc: 0.8948\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 339s 7ms/step - loss: 0.2061 - acc: 0.9229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x237903cf518>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model - currently training on 10 epochs only\n",
    "model.fit(X_train, Y_train, epochs = 10, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model for future use\n",
    "model.save('tmp/Model/apparel_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "reload_model = load_model('tmp/Model/apparel_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 14s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on cross validation set\n",
    "preds = model.evaluate(X_cv,Y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.31253336504101753\n",
      "Test Accuracy = 0.903\n"
     ]
    }
   ],
   "source": [
    "#Print the loss of cross validation set\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 14s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on test set\n",
    "preds_test = reload_model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.3361488898595174\n",
      "Test Accuracy = 0.8973333333333333\n"
     ]
    }
   ],
   "source": [
    "#Print the loss of test set\n",
    "print (\"Loss = \" + str(preds_test[0]))\n",
    "print (\"Test Accuracy = \" + str(preds_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert submission images data to numpy array from list\n",
    "test_x_np = np.asarray(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 3)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predit on submission image data\n",
    "test_predictions = model.predict(test_x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take argmax to get the highest probable class as the predictions will have probability of 10 classes\n",
    "test_preds = test_predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a data frame for submission\n",
    "submission_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['id']    = img_name_lst\n",
    "submission_df['label'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60001</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60005</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label\n",
       "0  60001      9\n",
       "1  60002      2\n",
       "2  60003      1\n",
       "3  60004      1\n",
       "4  60005      6"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
